Interested in the development of generalized learning mechanisms in artificial intelligence.

As to how such a mechanism could be obtained, I am not quite sure, however the emerging complexity arising from simpler (random?) processes seems like an approach I am interested in. I think at some point human algorithmic design breaks down, which seems to be something the research community often forgets. Of course there is a need for human design on some levels, however this inclusion of bias often reduces the flexibility of learning and design (e.g. fully-connected, ADAM, ReLU, etc). Can we design learning mechanisms such that both (meta-)learning and (meta-)architecural design emerge out the learning agent's own will/evolution? I think so.


<a href="https://scholar.google.com/citations?user=bQDooZEAAAAJ&hl=en">Google Scholar</a> / <a href="https://www.researchgate.net/profile/Samuel-Schmidgall">ResearchGate</a>

